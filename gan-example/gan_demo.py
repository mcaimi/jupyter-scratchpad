# -*- coding: utf-8 -*-
"""GAN Demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fNWS_R87vtSHHcUkazprycdmf8-IjV5V

**GAN Example with PyTorch, MatplotLib**

A simple implementation of a Generative Adversarial Network written with PyTorch

First of all we need some libraries that will be used throughout the demo:

*   PyTorch library (torch module)
*   The NeuralNetwork module (torch.nn module)
*   The DataLoader class which is used to load properly formatted train data (with optionally labels)
*   The torchvision module (specifically the transforms submodule and the make_grid function)
*   Finally the matplotlib module that will be used to display data visually

A freely available training data set will be used and imported directly from the torchvision module.

The FashionMNIST (originally from Zalando) includes 70K grayscale images of garments (28x28 pixels) grouped in 10 categories.

*   We will not build a supervised learning model, so the label set is not used in this example
*   The image dataset will be instead fed in an adversarial network to generate new images.
"""

# import pytorch and the NeuralNet library
import torch
import torch.nn as nn

# import the DataLoader utility class
# A dataset represents data and labels
# DataLoader wraps dataset into an iterable object
from torch.utils.data import DataLoader

# import vision-related utilities
from torchvision.transforms import ToTensor
from torchvision.utils import make_grid

# import dataset
from torchvision.datasets import FashionMNIST as dataset

# import pyplot for visualization
import matplotlib.pyplot as plt

# import python debugger
import pdb

# python OS library
import os

"""Let's also define an utility class to hold every non-nn related function.

We define some useful functions that can be used an re-used throughout the demo, to debug code or to display data from the training set.

* plot(): function that converts tensor data into a variable size grid of images and displays them using matplotlib
* download_dataset(): utility function that download the MNIST dataset from the network and returns DataLoader Iterator object
* get_processor_type(): queries pytorch for the underlying processor type. Automatically selects 'cpu' or 'cuda' as device type depending on hardware availability

The dataset iterator uses the batch_size variable to determine how many samples it needs to return to the caller for every iteration of the training process.

Upon load, the dataset needs to be converted to a [N x W x L] PyTorch Tensor from a [W x L x N] rgb image:
* transforms.ToTensor() method is used during the load operation to convert RGB data bytes to a Tensor
* the tensor.view() method is used to reshape the data array: training data comes in as a [N x K] array, where K = color depth x width x height. Output tensor is reshaped as [N x C x W x H]
"""

# Class utility: holds utility functions and code not directly related to the NN
# this will mostly contain only class methods
class Utilities(object):
  def __init__(self):
    super().__init__()

  # display data from the current tensor
  @classmethod
  def plot(self, tensor_data, channels=1, size=(28,28), num_items=16):
    print(f"Source Tensor({type(tensor_data)}): Shape {tensor_data.shape}")
    # we use detach() to remove this computation from the computation of back propagation parameters.
    # then, reshape the data to a meaningful representation for displaying images
    # original size: n x 768 (28*28) -> n * 1 * 28 * 28
    # whre n is the learning batch size
    plot_data = tensor_data.detach().cpu().view(-1, channels, *size)
    print(f"Reshaped Tensor({type(plot_data)}): Shape: {plot_data.shape}")

    # display data in a grid
    # matplotlib expects data with this format (rows, cols, channels)
    # tensor is now formatted like this (channels, rows, cols)
    # we need to swap data components
    display_grid = make_grid(plot_data[:num_items], nrow=int(num_items/4)).permute([1,2,0])
    print(f"Object type{type(display_grid)}")

    # show data
    plt.imshow(display_grid)
    plt.show()

  # download and prepare the dataset
  @classmethod
  def download_dataset(self, iterator=False, batch_size=128, download=True, shuffle=True, train_data=False):
    # get and load the dataset, return an iterator
    dataset_download = dataset('.', transform=ToTensor(), download=download, train=train_data)
    loaded_dataset = DataLoader(dataset_download, batch_size=batch_size, shuffle=shuffle)

    # return the iterator
    return iter(loaded_dataset) if iterator else loaded_dataset

  # explore dataset
  @classmethod
  def dataset_features(self, datapoint):
    if type(datapoint) == torch.Tensor:
      print(f"DataPoint {type(datapoint)}: dimensions: {datapoint.shape}")
    else:
      print("Not a Torch Tensor")

  # determine which kind of processing environment we can use
  @classmethod
  def get_processor_type(self):
    processor_device = 'cuda' if torch.cuda.is_available() else 'cpu'

    # return the detected processor type
    return processor_device

"""Now let's define the network parameters

*   Epochs (how many learning phases we will perform)

and some hyperparameters:

*   Batch Size (how many datpoints from the dataset we are going to process per iteration)
*   Learning Rate (a number that is used to tweak how fast the network is learning)
*   Latent Space Size (the indicative number of data features that the neural network is able to learn from data)

During each Epoch, the neural network will be fed a number of samples to analyze.

The dataset used in this demo contains 70K images:
* Each Epoch te network will process all images while progressively tuning its parameters according to a computed cost/loss function via backpropagation
* During each Epoch, data will be analyzed in batches of size B, so for each epoch, K=size(Dataset)/B iterations will be performed
"""

epochs = 100
batch_size = 128 # 128 images from the training set are fed to the neural network every iteration in an epoch
learning_rate = 0.0002
latent_space_size = 64 # number of features we'd like the network to learn from data

# generator image output size
gen_output_size = 28 * 28 # depends on training input data

# nn mode
# if train_mode is 0, assume no prior training, so train the network
# if train_mode is 1, skip training and load saved model
train_mode = 0

# model checkpoint file names
generator_model = "gan_generator_model.pth"
detector_model = "gan_detector_model.pth"

"""**Neural Network Generation Utilities**

This class implements utilities that will deal with the Neural Network implementation.

*   Method that generate a neuron block
*   Mehtods that generate synthetic data to feed to the neural network


"""

# The Neural Net block generator
class NeuralNetUtils(object):
  def __init__(self):
    super().__init__()

  # build a neural network node
  @classmethod
  def generate_sequential_linear_block(self, input_size, output_size):
    block = nn.Sequential( # a neural net layer, apply module sequentially
        nn.Linear(input_size, output_size),
        nn.BatchNorm1d(output_size),
        nn.ReLU(inplace=True)
    )
    return block

  # generate a random input image (noise input)
  # this return a structure with size [N x L] where N is the number of synthetic
  # data points and L is the size of the latent space
  @classmethod
  def random_std_noise(self, synthetic_datapoint_number, latent_space_size):
    return torch.randn(synthetic_datapoint_number, latent_space_size)

"""Declare both the Generator and the Detector neural networks.

* Generator class: generates a random image based on the neural net weights values. Outputs an array of values bounded between 0 and 1 representing a new image
* Detector class: evaluates input data based on the neural net weights. Output a single value, 0 if it detects a fake image, 1 if it detects a real image
"""

# Declare the Generator Neural Network
class Generator(nn.Module):
  def __init__(self, input_size, output_size, hidden_layer_size):
    super().__init__()
    self.generator = nn.Sequential(
        NeuralNetUtils.generate_sequential_linear_block(input_size, hidden_layer_size),
        NeuralNetUtils.generate_sequential_linear_block(hidden_layer_size, hidden_layer_size * 2),
        NeuralNetUtils.generate_sequential_linear_block(hidden_layer_size * 2, hidden_layer_size * 4),
        NeuralNetUtils.generate_sequential_linear_block(hidden_layer_size * 4, hidden_layer_size * 8),
        NeuralNetUtils.generate_sequential_linear_block(hidden_layer_size * 8, output_size),
        nn.Sigmoid() # normalize output between [0,1]
    )

  # generate next output
  def forward(self, input_data):
    return self.generator(input_data)

# Declare the Detector Neural Network
class Detector(nn.Module):
  def __init__(self, input_size, output_size, hidden_layer_size): # output is [0,1], real or fake
    super().__init__()
    self.detector = nn.Sequential(
        NeuralNetUtils.generate_sequential_linear_block(input_size, hidden_layer_size * 2),
        NeuralNetUtils.generate_sequential_linear_block(hidden_layer_size * 2, hidden_layer_size * 4),
        NeuralNetUtils.generate_sequential_linear_block(hidden_layer_size * 4, hidden_layer_size * 2),
        NeuralNetUtils.generate_sequential_linear_block(hidden_layer_size * 2, hidden_layer_size),
        nn.Linear(hidden_layer_size, 1)
    )

  # generate next output
  def forward(self, input_data):
    return self.detector(input_data)

"""Declare the actual GAN class

* Create a Generator and a Detector, and put them one against the other
* Use ADAM as the underlying parameter optimizer algorithm
* Generate images with the Generator (fake, from noise), attach output value of one, backpropagate
* Use the Detector to evaluate the output of the generator to a real image and compute the prediction, backpropagate

Also, declare some test and statistics functions to evaluate the training process
"""

# build the GAN object
class GenerativeNetwork(object):
  def __init__(self, dataset, input_size, output_size, hidden_layer_size, learning_rate, device):
    # dataset iterator
    self.data_iterator = dataset

    # params
    self.i_size = input_size
    self.o_size = output_size
    self.h_size = hidden_layer_size
    self.lr = learning_rate
    self.device = device

    # build the generator neural net
    self.generator = Generator(self.i_size, self.o_size, self.h_size).to(self.device)
    self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.lr)

    # build the detector neural net
    self.detector = Detector(self.o_size, 1, self.h_size).to(self.device)
    self.detector_optimizer = torch.optim.Adam(self.detector.parameters(), lr=self.lr)

  # generator loss function (Binary Cross Entropy)
  def generator_loss_function(self, batch_size, function=nn.BCELoss()):
    fake_input = NeuralNetUtils.random_std_noise(batch_size, self.i_size).to(self.device)
    synth_image = self.generator(fake_input)
    proof_image = self.detector(synth_image)
    weight_target = torch.ones_like(proof_image)
    return function(nn.Sigmoid()(proof_image), weight_target) # normalize input before computing loss

  # detector loss function
  def detector_loss_function(self, batch_size, batch_data, function=nn.BCELoss()):
    fake_input = NeuralNetUtils.random_std_noise(batch_size, self.i_size).to(self.device)
    synth_image = self.generator(fake_input)
    proof_image = self.detector(synth_image.detach()) #use data to calculate the detector loss but do not backpropagate on the generator
    gen_weight_target = torch.zeros_like(proof_image)
    gen_loss = function(nn.Sigmoid()(proof_image), gen_weight_target) # normalize input before computing loss

    train_image = self.detector(batch_data.to(self.device))
    dect_weight_target = torch.ones_like(train_image)
    dect_loss = function(nn.Sigmoid()(train_image), dect_weight_target) # normalize input before computing loss

    return (dect_loss + gen_loss)/2 # mean loss

  # train the model
  def train(self, batch_size, epochs):
    for e in range(epochs):
      print(f"\nCurrent Epoch: {e} -----------------------------")
      num_batches = len(self.data_iterator)
      iteration = 0
      # zero out statistics
      dect_loss = gen_loss = 0
      # training loop
      for train_data, _ in self.data_iterator:
        current_step = len(train_data)

        # train the generator
        self.generator_optimizer.zero_grad()
        generator_loss = self.generator_loss_function(batch_size)
        generator_loss.backward()
        self.generator_optimizer.step()

        # train the detector
        t_data = train_data.view(current_step, -1)
        t_data.to(device)

        self.detector_optimizer.zero_grad()
        detector_loss = self.detector_loss_function(current_step, t_data)
        detector_loss.backward()
        self.detector_optimizer.step()

        # update statistics
        iteration += 1
        dect_loss += detector_loss.item()/current_step
        gen_loss += generator_loss.item()/current_step
        print(f"\rProcessed {current_step} samples | Current Batch: [{iteration} / {num_batches}] | Epoch {100*iteration/num_batches:>1f}% | Generator Loss: {gen_loss} | Detector Loss: {dect_loss}",
              end="", flush=True)

# test model accuracy
def test(model, batch_size, device):
  # display progress
  accuracy = 0
  loss = 0

  fake_input = NeuralNetUtils.random_std_noise(batch_size, latent_space_size).to(device)
  fake = model.generator(fake_input)

  prediction = model.detector(fake.detach())

  print(prediction.argmax(1))
  accuracy = (prediction.argmax(1) == 1).type(torch.float).sum().item()
  print(f"Accuracy: {accuracy}% | Avg Loss: {loss:>7f}")

"""Start up and train the model on available hardware (CPU or GPU are autodetected)"""

# neural network setup and training process
device = Utilities.get_processor_type()
print(f"Device type: {device}")

# get the dataset
data_set = Utilities.download_dataset(batch_size=batch_size)

# instantiate the GAN Network
gan = GenerativeNetwork(data_set, latent_space_size, gen_output_size, 256, learning_rate, device)
# can we live-load a pre-trained model?
if train_mode == 0:
  if os.path.exists(generator_model):
    print(f"Loading model {generator_model}")
    gan.generator.load_state_dict(torch.load(generator_model))
  if os.path.exists(detector_model):
    print(f"Loading model {detector_model}")
    gan.detector.load_state_dict(torch.load(detector_model))

"""Train and save the resulting model."""

# start neural network training
if train_mode:
  gan.train(batch_size, epochs)
  torch.save(gan.generator.state_dict(), generator_model)
  torch.save(gan.detector.state_dict(), detector_model)

"""Now try to use the generator to output a new image and measure the network accuracy"""

fake = gan.generator(NeuralNetUtils.random_std_noise(batch_size, latent_space_size).to(device))
Utilities.plot(fake)
test(gan, batch_size, device)
